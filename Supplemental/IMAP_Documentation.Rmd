---
title: Documentation Robbins 
output: html_notebook
---
Documentation for the manuscript: "

### S1.1 Mortality and Vegetation Inputs
Here is the motality and vegetation calculates for the model, this requires CA_Plot, and CA_Tree data from the FIA 
https://www.fia.fs.fed.us/library/database-documentation/index.php

I downloaded the .csv version from 
https://apps.fs.usda.gov/fia/datamart/
on 5/29/2020

Setting up the librarys and independent functions. 

```{r}
library(sf)
library(rgdal)
library(plyr)
library(raster)
library(RColorBrewer)
library(dplyr)
options(scipen = 1e8)
Dark2<-brewer.pal(8,'Dark2')
ff<-function(x){
  return(as.numeric(as.character(x)))
}
Pal_1<-brewer.pal(9,"Set3")

'%!in%' <- function(x,y)!('%in%'(x,y))

dft<-function(x){as.data.frame(table(x))}
Dates=data.frame(Dates=seq(as.Date("2001-01-01"),as.Date("2018-01-01"),1))
```

### Getting the Plots Nessecary 

Here we subset the FIA record to the plots included in our study area and for the years of the study. 

```{r}

###Check for points per raster
Drive<-'C:/Users/zacha/Documents/GitHub/IMAP_Python_Project/Documentation/'
###Prepare Tree File
Years<-seq(2003,2018)

CA_Tree<-read.csv(paste0(Drive,'CA_TREE.csv'))
CA_Tree<-CA_Tree[CA_Tree$INVYR %in% Years,]

##Set projection for project 
proj<-("+init=epsg:4326 +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")


##FIA_Plot location 
CA_Plot<-read.csv(paste0(Drive,'CA_PLOT.csv'))
###Remove data without geolocation 
CA_Plot<-CA_Plot[!is.na(CA_Plot$LAT),]
CA_Plot<-CA_Plot[!is.na(CA_Plot$LON),]

###StudyArea to clip to 
SNV_Outline<-readOGR(paste0(Drive,"StudyArea/Study_Area.shp"))
# #To LAT:LONG
SNV_Outline<-spTransform(SNV_Outline,crs(proj))

#length(unique(CA_Plot$CN))
LL_Points<-cbind(CA_Plot['LON'],CA_Plot['LAT'])
LL_Points<-na.omit(LL_Points)

### Make into spatial points
sp_LL<-sp::SpatialPoints(LL_Points,proj4string = CRS(proj))

## Create the plots as a shape 
DT_sf = sf::st_as_sf(CA_Plot, coords = c("LON", "LAT"), 
                     crs = 4326, agr='constant')
#Do the Intesection
Plots_In_AOI<-sf::st_intersection(sf::st_as_sf(DT_sf),sf::st_as_sf(SNV_Outline))
### Get cordinates back
XYS<-st_coordinates(Plots_In_AOI)

###Check out geospatial locations
par(mar=c(5,5,5,5))
plot(sf::st_geometry(sf::st_as_sf(SNV_Outline)),axes=TRUE)
plot(sf::st_geometry(Plots_In_AOI),cex=.1,add=TRUE,axes=TRUE)

###Number of plots is 3505

### Find  the plots in that are in the area.  Remains at 3504 
Plots<-as.data.frame(CA_Plot[CA_Plot$CN %in% Plots_In_AOI$CN,])

### Get the elevation from each plot in meters
Plots$ELEV_m<-Plots$ELEV*.3408

```


This a group of functions used to parse out the nessecary data.

The first (SortPlots) parses the plots based on a range of latitude and longitude, 
filters out just the ponderosa pine, reduces the number of nessecary columns, 
and then creates a new column for Diameter in CM

The second (CalculateTrees) Calculates the trees for the inital condition 
it, looks at the trees in 2005/2006, subsets the trees into the two host groups (>31.8 cm and < 31.8 cm),
calates a TPA metric, and adjusts it to hectares

The third function calculates mortality for the subset of plots. It takes any of the relevant mortality conditionns,
and covers the others to NA, It then aggregates the total mortality on a tree per hectare basis per year. It subtracts
one year from the MortYR to account for the Year of infestation. It then calculates the mortality on a percentage basis
from the total trees of the sample. 

```{r}
#### This function subsets the dataset by the nessecary lat/elevation and sorts out 
#### unnessary species 

SortPlots<-function(one,Sp){
  ### Get the plots in the bounds 
  PltsSorted<-Plots[Plots$ELEV_m>one$LowEl & Plots$ELEV_m<one$HighEl,]
  PltsSorted<-PltsSorted[PltsSorted$LAT>one$LatLow & PltsSorted$LAT<one$LatHigh,]
  ### Subset the database by the plots 
  Subset<-CA_Tree %>%
    ### Get just one plot
    subset(CA_Tree$PLT_CN %in% PltsSorted$CN)%>%  # %>%
    ## Subset to just species of intrest (for now).
    subset(SPCD %in% Sp) %>%
    # ### Get Ht in M
    mutate(DIA_cm= (DIA*2.54))
  ###Get the nessecary columns
  Subset<-Subset[,c("PLT_CN","INVYR","SPCD","DIA_cm","MORTYR","AGENTCD","TPA_UNADJ")]
  hist(Subset$INVYR)
  UPY<-Subset %>%
    ##Group together by the inventory year and the plot number
    group_by(INVYR,PLT_CN)%>%
    ## For each plot number summarize the sum and entires for TPA_UNADJ
    ## This is the total count of stems on the site
    summarise_at(vars("TPA_UNADJ"),list(sum=sum,length=length))
  ### Remove entires with 0 TPA 
  HasTrees<-UPY[!is.na(UPY$sum),]
  ### Resubset by the plots that have trees 
  Relevent_Plots<-Subset[Subset$PLT_CN %in% HasTrees$PLT_CN,]
  return(Subset)
}


#### This calculates the initial population for each study site
CalculateTrees<-function(Subset){

  Subset<-Subset[Subset$INVYR%in%c(2005,2006),]
  All<-Subset[Subset$DIA_cm>10.0,]

  Lrg<-Subset[Subset$DIA_cm>31.8,]
  Smll<-Subset[Subset$DIA_cm< 31.8 & Subset$DIA_cm>10.0,]
  ### Get the years 2005,2006
  ### From this summarise the TPA_UNADJ 
  TPA_All<-All %>%
    group_by(INVYR,PLT_CN)%>%
    summarise_at(vars("TPA_UNADJ"),list(sum=sum))
  TotalPlots<-length(unique(TPA_All$PLT_CN))
  ###Take the mean and scale form Acre to HA. 
  TPA_Lrg<-Lrg %>%
    group_by(INVYR,PLT_CN)%>%
    summarise_at(vars("TPA_UNADJ"),list(sum=sum))
  TPA_Smll<-Smll %>%
    group_by(INVYR,PLT_CN)%>%
    summarise_at(vars("TPA_UNADJ"),list(sum=sum))
  
  (TPA_AllA<-(sum(TPA_All[,3],na.rm = T)*2.47105)/TotalPlots)
  (TPA_LrgA<-(sum(TPA_Lrg[,3],na.rm = T)*2.47105)/TotalPlots)
  (TPA_SmallA<-(sum(TPA_Smll[,3],na.rm = T)*2.47105)/TotalPlots)
  #(length(unique(TPA_1$PLT_CN))))
  ### Return results. 
  return(list(TPA_AllA,TPA_LrgA,TPA_SmallA))}




Cal_Mort<-function(Subset){
  Relevent_Plots<-Subset
  ### Remove plots that have any of the agent codes for fire, or harvest, vegetation, or unkown. 
  
  
  
  Relevent_Plots$MORTYR[Relevent_Plots$AGENTCD %in% c(30,40,60,70,80)]<-NA
  ### Summarize the given mortality year by the tpa_Unadj totaling the number of trees
  MORTYR<-Relevent_Plots %>%
    group_by(year=MORTYR)%>% 
    dplyr::summarise(n=sum(TPA_UNADJ))
  ### Subtract one year for attack year 
  MORTYR$year<-MORTYR$year-1
  ### Get the total trees surveyed in each year
  ALLYR<-Relevent_Plots %>%
    group_by(year=INVYR)%>% 
    dplyr::summarise(n=sum(TPA_UNADJ))
  ### Get the mean 
  ALLYR$mean=mean(ALLYR$n,na.rm=T)
  #ALLYR$Sum=sum(ALLYR$n)
  MortalityTable<-merge(MORTYR,ALLYR,by='year',all.y=T)
  MortalityTable[is.na(MortalityTable)]<-0
  ### Calculate mortality as the number of trees died / trees survyed + Trees died 
  MortalityTable$per<-MortalityTable$n.x/(MortalityTable$mean+MortalityTable$n.x)#(MortalityTable$n.y+MortalityTable$n.x)
  return(MortalityTable)
}
```

Here we set up the parameters for the functions. Sp=122 is Ponderosa pine in the FIA data
PltsLUT is a lookup table that contains, each location, the locations elevation and latitude bounds. 
It also includes all high latitude locations and all low latitude locations for comparison. 

```{r}
Sp=122

PltsLUT<-data.frame(Name=c("UpperLow","UpperMed","AllHighLatitude","LowerLow","LowerMed","AllLowLatitude"),
                    Patch=c(1,2,3,4,5,6),
                    LowEl=c(400,1400,400, 400,1500,400),
                    HighEl=c(1400,2000,2000,1500,2200,2200),
                    LatLow=c(37.5,37.5,37.5,33,33,33),
                    LatHigh=c(40,40,40,37.5,37.5,37.5))
```

Here is the number of plots per year in the northern locations 

```{r}
Subset_North<-SortPlots(PltsLUT[3,],Sp)
```
Here is the number of plots per year in the northern locations

```{r}
Subset_South<-SortPlots(PltsLUT[6,],Sp)
```

```{r}
Subset_All<-rbind(Subset_North,Subset_South)
OutTrees<-CalculateTrees(Subset_All)
print("Total PinuPond TPH")
print(OutTrees[[1]])
print("Total PinuPond TPH >31.6cm")
print(OutTrees[[2]])
print("Total PinuPond TPH <31.6cm")
print(OutTrees[[3]])

All<-Subset_All[ Subset_All$DIA_cm>10.0,]
All<-All[!is.na(All$PLT_CN),]
AllSub<-All[All$INVYR %in% c(2005,2006),]
Mort<-Cal_Mort(All)
barplot(Mort[[5]],names.arg=Mort[[1]],main="Percent Mortality Western Pine Beetle >10. cm",
        ylab="% Mortality",cex.main=1.5,cex.lab=1.2,cex.axis=1.2)
```

Trees larger than 31.8 cm

```{r}
Lrg<-Subset_All[Subset_All$DIA_cm>31.8,]
LrgSub<-Lrg[Lrg$INVYR %in% c(2005,2006),]
LrgMort<-Cal_Mort(Lrg)
barplot(LrgMort[[5]]*100,names.arg=LrgMort[[1]],main="Percent Mortality Western Pine Beetle >31.8 cm",
        ylab="% Mortality",cex.main=1.5,cex.lab=1.2,cex.axis=1.2)

```
```{r}

Smll<-Subset_All[Subset_All$DIA_cm< 31.8& Subset_All$DIA_cm>10.0,]
Smll<-Smll[!is.na(Smll$PLT_CN),]
SmllSub<-Smll[Smll$INVYR %in% c(2005,2006),]
SmllMort<-Cal_Mort(Smll)
barplot(SmllMort[[5]],names.arg=SmllMort[[1]],main="Percent Mortality Western Pine Beetle < 31.8 cm",
        ylab="% Mortality",cex.main=1.5,cex.lab=1.2,cex.axis=1.2,ylim=c(0,.2))
Output<-cbind(SmllMort[[1]],Mort[[5]],SmllMort[[5]],LrgMort[[5]])

```

This loop applies the observered mortality percentage to the inital population for the years 
2006-2018

```{r}
DF<-NULL
DF2<-NULL
#one<-PltsLUT[1,]

for(i in c(1,2,4,5)){
  #print(paste0("########### Plot ",i,"  ###################"))
  Subset<-SortPlots(PltsLUT[i,],Sp)
  Trees<-CalculateTrees(Subset)
  #print("All Trees")
  #print(Trees[[1]])
  #print("Large Trees")
  #print(Trees[[2]])
  #print("Small Trees")
  #print(Trees[[3]])
  Lrg<-Subset[Subset$DIA_cm >31.6,]
  #LrgSub<-Lrg[Lrg$INVYR %in% c(2005,2006),]
  Mortlrg<-Cal_Mort(Lrg)
  Mortlrg<-Mortlrg[Mortlrg$year %in% seq(2006,2018),]
  MortlrgPass<-data.frame(year= seq(2006,2018))
  MortlrgPass<-merge(MortlrgPass,Mortlrg,by="year",all.x=T)
  Mortlrg<-MortlrgPass
  Mortlrg$per[is.na(Mortlrg$per)]<-0
  #plot(Mortlrg[[5]],main=paste0("Large Mortality Site ", i ))
  #print("Percent Mort large")
  #print(sum(Mortlrg$per))
  Smll<-Subset[Subset$DIA_cm < 31.6 & Subset$DIA_cm > 10.0,]
  Smll<-Smll[!is.na(Smll$PLT_CN),]
  Mortsmll<-Cal_Mort(Smll)
  Mortsmll<-Mortsmll[Mortsmll$year %in% seq(2006,2018),]
  MortsmllPass<-data.frame(year= seq(2006,2018))
  MortsmllPass<-merge(MortsmllPass,Mortsmll,by="year",all.x=T)
  Mortsmll<-MortsmllPass
  Mortsmll$per[is.na(Mortsmll$per)]<-0
  #plot(Mortsmll[[5]],main=paste0("Small Mortality Site ", i ))
  #print("Percent Mort Small")
  #print(sum(Mortsmll$per))
 # barplot(Mortsmll[[6]],names.arg=Mortsmll[[1]])
#  Smlltree<-CalculateTrees(Smll)
  #Smlltree[1]
  Lrgtree<-Trees[[2]]
  Smlltree<-Trees[[3]]
  Mrs<-0
  Mrl<-0
  for(j in 1:13){
    #print(Ml)
    #print(Mortlrg[[1]][j])
    Ms<-Mortsmll[[5]][j]
    #print(Ms)
    Ml<-Mortlrg[[5]][j]
    #print(Ml)
    Smlltree<-c(Smlltree,Smlltree[j]-Smlltree[1]*Ms)
    Lrgtree<-c(Lrgtree,Lrgtree[j]-Lrgtree[1]*Ml)
    Mrs<-c(Mrs,Ms)
    Mrl<-c(Mrl,Ml)
  }
  Row<-c(PltsLUT[i,1],Lrgtree,Smlltree)
  DF<-rbind(Row,DF)
  Row2<-c(PltsLUT[i,1],Mrs,Mrl)
  DF2<-rbind(Row2,DF2)
}
DF2[is.na(DF2)]<-0
DF[is.na(DF)]<-0
DF_Out<-as.data.frame(DF)
colnames(DF_Out)<-c("Location","Initial_above_20","Large2006Perc","Large2007Perc","Large2008perc","Large2009perc",
                    "Large2010perc","Large2011perc","Large2012perc","Large2013perc",
                    "Large2014perc","Large2015perc",
                    "Large2016perc","Large2017perc","Large20018Perc","Initial_below_20",
                    "Small2006perc","Small2007perc","Small2008perc","Small2009perc",
                    "Small2010perc","Small2011perc","Small2012perc","Small2013perc",
                    "Small2014perc","Small2015perc","Small2016perc","Small2017perc","Small2018perc")

colnames(DF_Out)
DF_Out2<-DF_Out[,c(1,2,16,3:15,17:29)]

```

Here is the mortality of tree mortality per time step 

```{r}
Lrg<-as.data.frame(DF_Out2[,1:16])
Lrg<-Lrg[c(-1,-3)]
for(i in 1:length(colnames(Lrg))){
  Lrg[i]<-as.numeric(Lrg[[i]])
}
TreeSums<-colSums(Lrg)

#plot(seq(2005,2018,1),TreeSums,ylim=c(0,40))
Df=data.frame(Dates=seq(2006,2018,1),TreeMortality=TreeSums[1:13]-TreeSums[2:14],
              TreeTotal=TreeSums[1:13])
Df$Percent<-Df$TreeMortality/Df$TreeTotal
with(Df,barplot(Percent,names.arg=Dates,ylim=c(0,.60)))
```

The resulting mortality

```{r}
Df$PercentOrg<-Df$TreeMortality/Df$TreeTotal[1]
with(Df,barplot(PercentOrg,names.arg=Dates,ylim=c(0,1.0)))
```

```{r}
library(RColorBrewer)
Dark2<-brewer.pal(6,"Dark2")
#colnames(WPB3)
WPB3_plotter<-as.data.frame(DF_Out[,c(1:15)])
WPB3_plotter<-t(WPB3_plotter)
colnames(WPB3_plotter)<-WPB3_plotter[1,]
WPB3_plotter<-WPB3_plotter[-1,]
fix<-function(x){
  as.numeric(as.character(x))
}

Dates<-seq(
  from=as.POSIXct("2005-06-01 0:00", tz="UTC"),
  to=as.POSIXct("2018-06-01 0:00", tz="UTC"),
  by="year"
)  
#WPB3_plotter$Dates<-Dates

plot(WPB3_plotter[,1],ylim=c(0,80),xaxt='n',main="WPB Host(>31.8 cm) Tree Density Over Time",ylab="Tree Density Per Ha",xlab="Date",type="l",cex=1.5,cex.axis=1.5,cex.lab=1.5,lwd=3.0)
axis(1, at=1:14,labels =Dates, las=1,cex.axis=1.0,pch=15,cex=1.5,cex.axis=1.5,cex.lab=2.0)
##points(WPB3_plotter[,2],pch=16,col=Dark2[1],cex=1.5)
lines(WPB3_plotter[,2],lty=1,col=Dark2[2],cex=1.5,lwd=3.0)
#points(WPB3_plotter[,4],pch=18,col=Dark2[3],cex=1.5)
lines(WPB3_plotter[,3],lty=1,col=Dark2[4],cex=1.5,lwd=3.0)
lines(WPB3_plotter[,4],lty=1,col=Dark2[5],cex=1.5,lwd=3.0)
legend(10.0,80,legend=c("LowLat_HE","LowLat_LE","HighLat_HE","HighLat_LE"),cex=1.5,pch=c(15,15,15,15),col=c("Black",Dark2[2],Dark2[4],Dark2[5]))



```

```{r}
WPB3_plotter<-as.data.frame(DF_Out[,c(1,16:29)])
WPB3_plotter<-t(WPB3_plotter)
colnames(WPB3_plotter)<-WPB3_plotter[1,]
WPB3_plotter<-WPB3_plotter[-1,]
fix<-function(x){
  as.numeric(as.character(x))
}

Dates<-seq(
  from=as.POSIXct("2007-01-01 0:00", tz="UTC"),
  to=as.POSIXct("2017-01-01 0:00", tz="UTC"),
  by="year"
)  

plot(WPB3_plotter[,1],ylim=c(0,150),xaxt='n',main="WPB Host(<31.8 cm) Tree Density Over Time",ylab="Tree Density Per Ha",xlab="Date",type="l",cex=1.5,cex.axis=1.5,cex.lab=1.5,lwd=3.0)
axis(1, at=1:11,labels =Dates, las=1,cex.axis=1.0,pch=15,cex=1.5,cex.axis=1.5,cex.lab=2.0)
##points(WPB3_plotter[,2],pch=16,col=Dark2[1],cex=1.5)
lines(WPB3_plotter[,2],lty=1,col=Dark2[2],cex=1.5,lwd=3.0)
#points(WPB3_plotter[,4],pch=18,col=Dark2[3],cex=1.5)
lines(WPB3_plotter[,3],lty=1,col=Dark2[4],cex=1.5,lwd=3.0)
lines(WPB3_plotter[,4],lty=1,col=Dark2[5],cex=1.5,lwd=3.0)
legend(9.0,150,legend=c("LowLat_HE","LowLat_LE","HighLat_HE","HighLat_LE"),cex=1.5,pch=c(15,15,15,15),col=c("Black",Dark2[2],Dark2[4],Dark2[5]))

```

Here we set up columns and write to the output. 

```{r,eval=FALSE}
DF_Out<-as.data.frame(DF)
DF[is.na(DF)]<-0
DF_Out<-as.data.frame(DF)
colnames(DF_Out)<-c("Location","Initial_above_20","Large2006Perc","Large2007Perc","Large2008perc","Large2009perc",
                    "Large2010perc","Large2011perc","Large2012perc","Large2013perc",
                    "Large2014perc","Large2015perc",
                    "Large2016perc","Large2017perc","Large20018Perc","Initial_below_20",
                    "Small2006perc","Small2007perc","Small2008perc","Small2009perc",
                    "Small2010perc","Small2011perc","Small2012perc","Small2013perc",
                    "Small2014perc","Small2015perc","Small2016perc","Small2017perc","Small2018perc")

colnames(DF_Out)
DF_Out2<-DF_Out[,c(1,2,16,3:15,17:29)]
#write.csv(DF_Out2,paste0(Drive,"/WPB_Model/WPB_Inputs/WPB_Trees_6_20.csv"))
```


## S1.2 Climate Inputs 

Here is the code to get the climate inputs, I have set it to not evalutate here because it requires a number of 
Daymet inputs that need to download from 
https://daac.ornl.gov/cgi-bin/dsviewer.pl?ds_id=1328
These are rather large.

Description:
This dataset provides Daymet Version 3 model output data as gridded estimates of daily weather parameters for North America and Hawaii: including Canada, Mexico, the United States of America, and Puerto Rico. The island areas of Hawaii and Puerto Rico are available as files separate from the continental land mass. Daymet output variables include the following parameters: minimum temperature, maximum temperature, precipitation, shortwave radiation, vapor pressure, snow water equivalent, and day length. The dataset covers the period from January 1, 1980 to December 31 of the most recent full calendar year. Each subsequent year is processed individually at the close of a calendar year. Daymet variables are continuous surfaces provided as individual files, by variable and year, at a 1-km x 1-km spatial resolution and a daily temporal resolution. Data are in a Lambert Conformal Conic projection for North America and are distributed in a netCDF file format compliant with Climate and Forecast (CF) metadata conventions (version 1.6).

I included one Daymet file for demostration

```{r,}
library(raster)
library(rgdal)
library(dplyr)
###This is the drive where all the climate files are 

Drive<-"C:/Users/zacha/Documents/Github/IMAP_Python_Project/Inputs/StudyArea/"
### Get all the files in the percipitaiton  
files<-list.files(paste0(Drive,"Tmax/"),pattern = "\\.nc4$" )
# Grab an example file
file<-files[1]
# Here are all of the shape files made above
Low_LowElShape<-readOGR(paste0(Drive,"StudyArea/WPB_Low_Low.shp"),verbose = FALSE)
Low_MedElShape<-readOGR(paste0(Drive,"StudyArea/WPB_Low_High.shp"),verbose = FALSE)
High_LowElShape<-readOGR(paste0(Drive,"StudyArea/WPB_High_Low.shp"),verbose = FALSE)
High_MedElShape<-readOGR(paste0(Drive,"StudyArea/WPB_High_High.shp"),verbose = FALSE)

##Grab and example file 
TC_CWD<- raster(paste0(Drive,"Tmax/",file))
####The assigned projection for Daymet. From the website 
projection(TC_CWD)<- "+proj=lcc +lat_1=25 +lat_2=60 +lat_0=42.5 +lon_0=-100 +x_0=0 +y_0=0 +a=6378137 +b=6356752.314706705 +units=m +no_defs"
### Transform all the shapefiles to the NC format. 
Low_LowElShape_re<-spTransform(Low_LowElShape,crs(TC_CWD))
Low_MedElShape_re<-spTransform(Low_MedElShape,crs(TC_CWD))
High_LowElShape_re<-spTransform(High_LowElShape,crs(TC_CWD))
High_MedElShape_re<-spTransform(High_MedElShape,crs(TC_CWD))

```

Visualizing where everything lines up 

```{r}

### Here is some visualization to show where eveyrthing is. 
CA_Shape<-readOGR("C:/Users/zjrobbin/Documents/GitHub/IMAP_Python_Project/Inputs/StudyArea/CA_5070.shp",verbose = FALSE)
Shape_re<-spTransform(Low_LowElShape,crs(TC_CWD))
Shape_re3<-spTransform(CA_Shape,crs(TC_CWD))

par(mfrow=c(1,2))

## Here is a up close of the areas 
plot(TC_CWD,xlim=c(-2000000,-1000000),ylim=c(-1000000,0))
plot(Shape_re,add=TRUE,col="black")
plot(Low_MedElShape_re[1],border="red",add=TRUE)
plot(Low_HighElShape_re[1],border="blue",add=TRUE)
plot(High_LowElShape_re[1],border="green",add=TRUE)
plot(High_MedElShape_re[1],border="red",add=TRUE)
plot(High_HighElShape_re[1],border="yellow",add=TRUE)
plot(Shape_re3[1],col=NA,border="black", add=TRUE)
### Here is the projection on a large scale 
plot(TC_CWD)
plot(Shape_re,add=TRUE,col="black")
#plot(Shape_re2,add=TRUE)
plot(Shape_re3[1],col=NA,border="black", add=TRUE)
```

This the function that masks and means the value for each layer in the stack of temp/PPT values

```{r}
df<-NULL
### Read in the files for temperature max
files<-list.files(paste0(DayMet_dir,"tmax/"),pattern = "\\.nc4$" )
### This is the function we use to process it takes as an input on of NC files.
### and one of the plot shape files.
DaymetProcessor<-function(TC_CWD,AOI){
 ### Take the .nc  
 Output <-TC_CWD %>%
   ## Cropt the outline to the AOI
   crop(y=AOI)%>%
   ## Then mask it 
   mask(mask=AOI)%>%
   ## Make it a dataframe
   as.data.frame() %>%
   ## Then take the mean from it 
   colMeans(na.rm = TRUE)
 ## Return it 
 return(Output)
}
```

Here we process temperature maximum 

```{r,eval=F}
## For this loop we loop through each yearly file. 

### Same as the above but for temp mean 
DayMet_dir<-"E:/Daymet/"

#setwd(w_dir)
print(files)
df<-NULL
files<-list.files(paste0(DayMet_dir,"Tmax/"),pattern = "\\.nc4$" )
for(i in files){
  ###Time tracking, This will take a while.
  ptm <- proc.time()
  ### Load in the raster brick for one year. 
  TC_CWD<- brick(paste0(DayMet_dir,"Tmax/",i))
  ### Run the above processs for each plot.
  Low_LowElShape_Out<-DaymetProcessor(TC_CWD,Low_LowElShape_re)
  Low_MedElShape_Out<-DaymetProcessor(TC_CWD,Low_MedElShape_re)
  Low_HighElShape_Out<-DaymetProcessor(TC_CWD,Low_HighElShape_re)
  High_LowElShape_Out<-DaymetProcessor(TC_CWD,High_LowElShape_re)
  High_MedElShape_Out<-DaymetProcessor(TC_CWD,High_MedElShape_re)
  High_HighElShape_Out<-DaymetProcessor(TC_CWD,High_HighElShape_re)
  ### Get the dates from one of the bricks 
  Names<- as.Date(names(TC_CWD),tryFormats = c("X %Y.%m.%d"))
  ### Create a data frame from it. 
  Year<-cbind(as.character(Names),Low_LowElShape_Out,
              Low_MedElShape_Out,Low_HighElShape_Out,
              High_LowElShape_Out,High_MedElShape_Out,High_HighElShape_Out)
  ### End time 
  print(proc.time() - ptm)
  df<-rbind(Year,df)

}

#write.csv(df,"C:/Users/zjrobbin/Documents/GitHub/IMAP_Python_Project/Input_Data_Scripts/WPB_Tmax_1_24.csv")


```

Processing Minimum temperature

```{r}
df<-NULL
### Same as the above but for temp min
DayMet_dir<-"E:/Daymet/"

#setwd(w_dir)
print(files)

files<-list.files(paste0(DayMet_dir,"Tmin/"),pattern = "\\.nc4$" )
for(i in files){
  print(i)
  ptm <- proc.time()
  TC_CWD<- brick(paste0(DayMet_dir,"Tmin/",i))
  Low_LowElShape_Out<-DaymetProcessor(TC_CWD,Low_LowElShape_re)
  Low_MedElShape_Out<-DaymetProcessor(TC_CWD,Low_MedElShape_re)
  Low_HighElShape_Out<-DaymetProcessor(TC_CWD,Low_HighElShape_re)
  High_LowElShape_Out<-DaymetProcessor(TC_CWD,High_LowElShape_re)
  High_MedElShape_Out<-DaymetProcessor(TC_CWD,High_MedElShape_re)
  High_HighElShape_Out<-DaymetProcessor(TC_CWD,High_HighElShape_re)
  Names<- as.Date(names(TC_CWD),tryFormats = c("X %Y.%m.%d"))

  Year<-cbind(as.character(Names),Low_LowElShape_Out,
              Low_MedElShape_Out,Low_HighElShape_Out,
              High_LowElShape_Out,High_MedElShape_Out,High_HighElShape_Out)
  print(proc.time() - ptm)
  df<-rbind(Year,df)
}

#write.csv(df,"C:/Users/zjrobbin/Documents/GitHub/IMAP_Python_Project/Input_Data_Scripts/WPB_Tmin_1_14.csv")
```

# Processing PPT

```{r}
df<-NULL
DayMet_dir<-"E:/Daymet/"
#setwd(w_dir)

### Same as the above but for ppt 
files<-list.files(paste0(DayMet_dir,"Prcp/"),pattern = "\\.nc4$" )
for(i in files){
  print(i)
  ptm <- proc.time()
  TC_CWD<- brick(paste0(DayMet_dir,"Prcp/",i))
  Low_LowElShape_Out<-DaymetProcessor(TC_CWD,Low_LowElShape_re)
  Low_MedElShape_Out<-DaymetProcessor(TC_CWD,Low_MedElShape_re)
  Low_HighElShape_Out<-DaymetProcessor(TC_CWD,Low_HighElShape_re)
  High_LowElShape_Out<-DaymetProcessor(TC_CWD,High_LowElShape_re)
  High_MedElShape_Out<-DaymetProcessor(TC_CWD,High_MedElShape_re)
  High_HighElShape_Out<-DaymetProcessor(TC_CWD,High_HighElShape_re)
  Names<- as.Date(names(TC_CWD),tryFormats = c("X %Y.%m.%d"))
  
  Year<-cbind(as.character(Names),Low_LowElShape_Out,
              Low_MedElShape_Out,Low_HighElShape_Out,
              High_LowElShape_Out,High_MedElShape_Out,High_HighElShape_Out)
  print(proc.time() - ptm)
  df<-rbind(Year,df)
}

write.csv(df,"C:/Users/zjrobbin/Documents/GitHub/IMAP_Python_Project/Input_Data_Scripts/WPB_Prcp_1_14.csv")
```


From the percipitaiton data we calculate the SPI- 4 Year Index 

```{r,fig.width=10.0,fig.height=10.0}
library(RColorBrewer)
library(rcarbon)
library(RcppRoll)
library(lubridate)
ff<-function(x){
  return(as.numeric(as.character(x)))
}
#display.brewer.all()
Pal_1<-brewer.pal(9,"Set3")

PPT_in<-read.csv("C:/Users/zacha/Documents/GitHub/IMAP_Python_Project/WPB_Model/WPB_Inputs/WPB_Prcp_1_14.csv")
colnames(PPT_in)<-c(paste0(colnames(PPT_in),"PRCP"))
colnames(PPT_in)[2]<-"Dates"
PPT_in<-PPT_in[-1]
PPT_in$Dates<-as.Date(PPT_in$Dates)

Dates<-as.Date(seq(
  from=as.POSIXct("1995-01-01 0:00", tz="UTC"),
  to=as.POSIXct("2018-12-31 0:00", tz="UTC"),
  by="day"
) )


Dates2<-as.Date(seq(
  from=as.POSIXct("1995-01-01 0:00", tz="UTC"),
  to=as.POSIXct("2005-01-01 0:00", tz="UTC"),
  by="day"
) )## Was 2012

PPT_sub<-PPT_in[PPT_in$Dates %in% as.Date(Dates2),]
PPT_sub<-PPT_sub[order(PPT_sub$Dates),]
LE_LL_Roll<-roll_sum(PPT_sub$Low_LowElShape_OutPRCP,1460)
LE_LL_Mean<-mean(LE_LL_Roll)
LE_LL_SD<-sd(LE_LL_Roll)
ME_LL_Roll<-roll_sum(PPT_sub$Low_MedElShape_OutPRCP,1460)
ME_LL_Mean<-mean(ME_LL_Roll)
ME_LL_SD<-sd(ME_LL_Roll)     
LE_HL_Roll<-roll_sum(PPT_sub$High_LowElShape_OutPRCP,1460)
LE_HL_Mean<-mean(LE_HL_Roll)
LE_HL_SD<-sd(LE_HL_Roll)
HE_HL_Roll<-roll_sum(PPT_sub$High_MedElShape_OutPRCP,1460)
HE_HL_Mean<-mean(HE_HL_Roll)
HE_HL_SD<-sd(HE_HL_Roll)

PPT<-PPT_in[PPT_in$Dates %in% as.Date(Dates),]
PPT<-PPT[PPT$Dates>"1997-01-01",]
PPT<-PPT[order(PPT$Dates),]

#plot(as.Date(Dates)[1460:6206],(roll_sum(PPT$Low_LowElShape_OutPRCP,1460)-LE_LL_Mean)/LE_LL_SD)

par(mar=c(5,5,5,5),xpd=F)
plot(as.Date(PPT$Dates)[1460:8029],(roll_sum(PPT$High_MedElShape_OutPRCP,1460)-HE_HL_Mean)/HE_HL_SD,
     col=adjustcolor(Pal_1[4],alpha.f=.5),ylim=c(-3,1.0),
     ylab="Drought Index",xlab="Year",cex.axis=2.0,cex.lab=2.0,cex.main=2.0,type="l",lwd=3.0,
     main="Four year SPI ")
points(as.Date(PPT$Dates)[1460:8029],(roll_sum(PPT$High_LowElShape_OutPRCP,1460)-LE_HL_Mean)/LE_HL_SD,
       col=adjustcolor(Pal_1[5],alpha.f=.5),type="l",lwd=3.0)
#points(as.Date(together[,1]),cumsum(Delta_df$Low_MedElDelta-mean(Delta_df_sub$Low_MedElDelta))/19)
points(as.Date(PPT$Dates)[1460:8029],(roll_sum(PPT$Low_LowElShape_OutPRCP,1460)-LE_LL_Mean)/LE_LL_SD,
       col=adjustcolor(Pal_1[1],alpha.f=.5),type="l",lwd=3.0)
points(as.Date(PPT$Dates)[1460:8029],(roll_sum(PPT$Low_MedElShape_OutPRCP,1460)-ME_LL_Mean)/ME_LL_SD,
       col=adjustcolor(Pal_1[3],alpha.f=.5),type="l",lwd=3.0)

abline(h=0)
abline(v=as.Date("2013-06-15"),lty=2.0)
abline(v=as.Date("2014-06-15"),lty=3.0)
abline(v=as.Date("2015-06-15"),lty=4.0)
abline(v=as.Date("2016-06-15"),lty=5.0)

legend(as.Date("2001-09-01"),-2.0,legend=c("Low Elevation/Low Lat","High Elevation/Low Lat",
                                              "Low Elevation/High Lat","High Elevation/High Lat",
                                              "Beetle Mortality %","July of a given Year"),
         pch=c(16,16,16,16,16,NA),lty=c(NA,NA,NA,NA,NA,1),col=c(Pal_1[1],Pal_1[3],Pal_1[4],Pal_1[5],"black","black"),
         cex=1.5)



PPT<-PPT_in[PPT_in$Dates %in% as.Date(Dates),]
PPT<-PPT[PPT$Dates>"1997-01-01",]
PPT<-PPT[order(PPT$Dates),]

SPI_DF=data.frame(Dates=(as.Date(PPT$Dates)[1460:8029]),
                  HE_HL=(roll_sum(PPT$High_MedElShape_OutPRCP,1460)-HE_HL_Mean)/HE_HL_SD,
                  LE_HL=(roll_sum(PPT$High_LowElShape_OutPRCP,1460)-LE_HL_Mean)/LE_HL_SD,
                  LE_LL=(roll_sum(PPT$Low_LowElShape_OutPRCP,1460)-LE_LL_Mean)/LE_LL_SD,
                  HE_LL=(roll_sum(PPT$Low_MedElShape_OutPRCP,1460)-ME_LL_Mean)/ME_LL_SD
                  )




#write.csv(SPI_DF,"C:/Users/zacha/Documents/GitHub/IMAP_Python_Project/WPB_Model/WPB_Inputs/WPB_SPI_620.csv")



```

### Inputs and Plotting 





### Calculating intial population range from 
Hayes, C. J., Fettig, C. J., & Merrill, L. D. (2009). Evaluation of multiple funnel traps and stand characteristics for estimating western pine beetle-caused tree mortality. Journal of economic entomology, 102(6), 2170-2182.
https://doi-org.prox.lib.ncsu.edu/10.1603/029.102.0621
https://academic-oup-com.prox.lib.ncsu.edu/jee/article/102/6/2170/2199328

Using the capture data and using the model inputs on fecondunity we back calculate the number of parents to 
reach these population levels. The high and low bounds are used as the intial population bounds for 
paramterization 

```{r}
#Initial Populations:
#From Hayes Endemic Values=33.4-67.8 trapped per day 
## Surveyed 28 may to Oct 15
## This is 140 day s
Lb=33.4*140*.5
#Ub=67.8*140*.5
### If we included "Building populations
#Lb=78.8*140*.5
Ub=126.7*140*.5

#Mortality rate is
Mr=.142857
#FecRate
Fr=24

### To calulate parents we assume
### Reverse the non-winter year mortality rate 
SurvivalLb=Lb/(Mr)
SurvivalUb=Ub/(Mr)
##

InitialPopLb=SurvivalLb/Fr
InitialPopUb=SurvivalUb/Fr
### If we assume 3 generations a year 
InitialPopLb/3
InitialPopUb/3
```


```{r}

```

